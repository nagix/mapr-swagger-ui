#!/usr/bin/python

from lxml import etree
from pyquery import PyQuery as pq
import os
import re
import sys

filename = 'mapr.yaml'
baseurl = 'http://maprdocs.mapr.com/home/ReferenceGuide/maprcli-REST-API-Syntax.html'
enums = {}

# Escape HTML text
def escape(text):
  return (text or '').replace('<', '&lt;').replace('>', '&gt;')

# Remove unnecessary spaces
def trim(text):
  return re.sub(r'\s+', ' ', text)

# Adjust spaces and line breaks
def normalize(d):
  pre_descendant = d('pre *')
  for e in d('*'):
    if e in pre_descendant:
      e.text = escape(e.text).replace('\n', '\n\n')
      e.tail = escape(e.tail).replace('\n', '\n\n')
    else:
      if e.tag == 'pre':
        e.text = escape(e.text).replace('\n', '\n\n')
      else:
        e.text = trim(escape(e.text))
      e.tail = trim(escape(e.tail))
  return d

# Replace HTML tags with Markdown
def replace_tags(d, selector, start, end):
  elements = d.find(selector)
  for e in reversed(elements):
    html = escape(e.text)
    children = e.getchildren()
    if children:
      html += unicode('').join([etree.tostring(c) for c in children])
    href = e.get('href') or ''
    if href:
      href = '(%s)' % href
    tail = escape(e.tail)
    pq(e).before(start + html + end + href + tail)
    parent = e.getparent()
    parent.remove(e)
  return elements

# Get the GFM representation of sub nodes
def gfm(d):
  s = d.clone().wrap_all('<section></section>')
  normalize(s)
  replace_tags(s, 'h2', '\n\n## ', '\n\n')
  replace_tags(s, 'strong','**', '**')
  replace_tags(s, 'code a', '[`', '`]')
  replace_tags(s, 'pre code,code:contains("`")', '', '')
  replace_tags(s, 'code', '`', '`')
  replace_tags(s, 'a', '[', ']')
  replace_tags(s, 'ul dl', '', '')
  replace_tags(s, 'ul dt', '**', '**<br>')
  replace_tags(s, 'ul dd', '', '<br>')
  replace_tags(s, 'dl', '\n\n\n', '')
  replace_tags(s, 'dt', '**', '**\n\n\n')
  replace_tags(s, 'dd', '', '\n\n\n')
  replace_tags(s, 'ul ul li', '\n  * ', '\n')
  replace_tags(s, 'ul ul', '', '')
  replace_tags(s, 'ul li', '\n* ', '\n')
  replace_tags(s, 'ol li', '\n1. ', '\n')
  replace_tags(s, 'ul,ol', '\n', '\n\n\n')
  replace_tags(s, 'section,td,p,div', '\n\n\n', '\n\n\n')
  replace_tags(s, 'pre', '\n\n\n```\n\n', '\n\n```\n\n\n')
  replace_tags(s, 'span', '', '')
  s('*').remove_attr('class')
  return (s.html() or '').strip()

# Parse enum
def parse_enum(name, d, syntax):

  # Parse from syntax
  match = re.search(r'-%s[^\]\n]+?([\w \|]+\| *\w+)' % name, syntax)
  if match:
    enum = []
    for i in match.group(1).split('|'):
      if re.search(r'\W', i.strip()):
        break
      enum.append(i.strip())
    else:
      return enum

  # Parse from a list
  if d('ul'):
    enum = []
    for i in d('ul:first li').items():
      value = re.search(r'\S(?:[\w\s/]*[\w*])?', i.text(), re.S).group()
      if re.search(r'\W', value):
        break
      enum.append(value)
    else:
      return enum

  # Parse from a text
  match = None
  if name in ['output', 'replicationtype', 'type']:
    match = re.search(r'(\w+)(?: \(.+?\))? or (\w+)', d.text(), re.S)
  elif name in ['tabletype']:
    match = re.search(r'(\w+) and (\w+)', d.text(), re.S)  
  if match:
    return match.groups()

  return []

# Detect type
def detect_type(name, description, syntax):
  if re.search(r'-%s[^\]\n]+(true|false)' % name, syntax):
    return 'boolean'
  elif re.search(r'default\s+is\s+(true|false)', description):
    return 'boolean'
  return 'string'

# Print headers
def print_headers(d):

  # Print info
  print('swagger: "2.0"')
  print('info:')
  print('  title: MapR API')
  print('  description: The information about the MapR REST API')
  print('  contact:')
  print('    url: http://maprdocs.mapr.com')

  # Print version
  version = d('meta[name=version]').attr.content
  print('  version: "%s"' % version)

  # Print other headers
  print('basePath: /rest')
  print('schemes:')
  print('  - https')
  print('produces:')
  print('  - application/json')
  print('securityDefinitions:')
  print('  BasicAuth:')
  print('    type: basic')
  print('security:')
  print('  - BasicAuth: []')
  print('paths:')

# Print command
def print_command(d, tag):

  # Get command path
  syntax = d('h2,p')('*:contains("Syntax") ~ *').text()
  if not syntax:
    syntax = d('dt:contains("REST")').parent().text()
  match = re.search('(?<=rest)/[a-z\-/<>]+', syntax)
  if not match:
    return
  path = match.group().replace('<','{').replace('>','}')

  # Print progress
  sys.stderr.write('\r\033[KProcessing %s...' % path)

  # Print summary and description
  short_desc = d('.shortdesc') or d('p:first')
  summary = trim(short_desc.text())
  if short_desc.next().find('p:contains("Syntax")'):
    content = short_desc.next().children()
  else:
    content = short_desc.next_all()
  elements = []
  for e in content:
    if pq(e)('h2,p')('*:contains("Syntax")'):
      break
    if pq(e)('dt:contains("REST")'):
      break
    elements.append(e)
  description = gfm(pq(elements))
  print('  %s:' % path)
  print('    get:')
  print('      tags:')
  print('        - %s' % tag)
  print('      summary: "%s"' % summary)
  print('      description: "%s"' % description)
  print('      externalDocs:')
  print('        url: %s' % d.base_url)

  # Print parameters
  parameters = d('h2,p')('*:contains("Parameters") ~ * tbody').eq(0)
  if not parameters:
    parameters = d('th:contains("Parameter")').closest('table').find('tbody')
  if parameters:
    print('      parameters:')
    for i in parameters('tr').items():
      parameter = [j for j in i('td').items()]
      name = trim(parameter[0].text())

      if re.search(r'(json|long)$', name):
        continue

      in_ = 'query'
      description = gfm(parameter[1])
      required = parameter[0]('strong')
      if 'urls' in d.base_url and name == 'name':
        in_ = 'path'
        required = True
      type = detect_type(name, parameter[1].text(), syntax)
      enum = parse_enum(name, parameter[1], syntax)
      if path == '/node/list' and name == 'columns':
        type = 'array'
        enum = enums['node']
      elif re.search(r'/volume/(info|list)', path) and name == 'columns':
        type = 'array'
        enum = enums['volume']
      elif path == '/volume/snapshot/list' and name == 'columns':
        type = 'array'
        enum = enums['volume snapshot list']
      print('        - name: %s' % name)
      print('          in: %s' % in_)
      if '"' in description:
        print('          description: \'%s\'' % description)
      else:
        print('          description: "%s"' % description)
      if required:
        print('          required: true')
      print('          type: %s' % type)
      if type == 'array':
        print('          items: {')
        print('            type: string')
        print('          }')
        print('          collectionFormat: csv')
      if enum:
        print('          enum:')
        for value in enum:
          print('            - %s' % value)

  # Print responses
  print('      responses:')
  print('        200:')
  print('          description: OK')

# Get enum from field table
def get_enum(d, tag):
  if tag not in ['node', 'volume', 'volume snapshot list']:
    return
  fields = d('h2')('*:contains("Fields") ~ * tbody').eq(0)
  if fields:
    enums[tag] = []
    for i in fields('tr').items():
      enums[tag].append(i('td:first').text())

# Find and print command
def find_command(links, cat=None):
  for e in links:
    category = cat
    if not cat:
      category = e.text
    d = pq(e.get('href')).make_links_absolute()
    get_enum(d, e.text)
    sublinks = d('.link a')
    if sublinks:
      find_command(sublinks, category)
    else:
      print_command(d, category)

# Main
with open(os.path.join(os.path.dirname(__file__), filename), "w") as sys.stdout:
  d = pq(baseurl).make_links_absolute()
  print_headers(d)
  find_command(d('.link:gt(0) a'))

sys.stderr.write('\r\033[K')
sys.stderr.flush()
